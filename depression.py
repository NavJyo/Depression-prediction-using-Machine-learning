# -*- coding: utf-8 -*-
"""DEPRESSION.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15RGSt-aoU1IwMR3yIj3H4VJjE6MRS1Th
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from matplotlib.pyplot import figure
from sklearn.metrics import confusion_matrix
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
import pickle
import sklearn
import scipy
sns.set()

df=pd.read_csv('b_depressed.csv') 
#dataset=df.values

df.head()

df.shape

df.info()

df.describe().T

data_feature = df.columns

#for feature in data_feature:
#    p = sns.distplot(a = df[feature])
#    plt.show()

#df_zeros = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']

#df[df_zeros] = np.where((df[df_zeros] == 0), np.nan, df[df_zeros])

df= df.dropna(axis='rows')

#df.isnull().sum()

p = df.hist(figsize = (8,10))

df.describe().T

df['Number_children'] = df['Number_children'].fillna(df['Number_children'].mean())

#sns.boxplot(y = 'SkinThickness', data = df)

#df['SkinThickness'].mean(), df['SkinThickness'].median()

#df['SkinThickness'] = df['SkinThickness'].fillna(df['SkinThickness'].median())

#df['Insulin'].mean(), df['Insulin'].median()

#df['Insulin'] = df['Insulin'].fillna(df['Insulin'].median())

#df['BMI'].mean(), df['BMI'].median()

#df['BMI'] = df['BMI'].fillna(df['BMI'].median())

for i in range(12):
    print(df.columns[i])

p = df.hist(figsize = (10,10))

sns.pairplot(data =df)
plt.show()

plt.figure(figsize=(15,15))
sns.heatmap(df.corr(), annot = True, cmap = "CMRmap")
plt.show()

from scipy import stats
for feature in df.columns:
    stats.probplot(df[feature], plot = plt)
    plt.title(feature)
    plt.show()

from sklearn.preprocessing import StandardScaler
scale = StandardScaler()

df.head()

from sklearn.preprocessing import MinMaxScaler 
from sklearn.preprocessing import StandardScaler 
scaler=StandardScaler()
scaler.fit(df) 
scaled_data=scaler.transform(df) 
scaled_data

from sklearn.decomposition import PCA 

pca=PCA(n_components=11) 

pca.fit(scaled_data) 
x_pca=pca.transform(scaled_data)

scaled_data.shape

x_pca.shape

from sklearn.model_selection import train_test_split 
y = df.iloc[:, -1] 
X_train, X_test, y_train, y_test = train_test_split(x_pca, y, test_size = 0.2, random_state = 0)

#X = df.iloc[:, :-1]
#y = df.iloc[:, -1]

#X.head()

#y.head()

#X.head()

#from sklearn.model_selection import train_test_split
#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)

def svm_classifier(X_train, X_test, y_train, y_test):
    
    classifier_svm = SVC(kernel = 'rbf', random_state = 0)
    classifier_svm.fit(X_train, y_train)

    y_pred = classifier_svm.predict(X_test)

    cm = confusion_matrix(y_test, y_pred)

    return print(f"Train score : {classifier_svm.score(X_train, y_train)}\nTest score : {classifier_svm.score(X_test, y_test)}")

def knn_classifier(X_train, X_test, y_train, y_test):
    
    classifier_knn = KNeighborsClassifier(metric = 'minkowski', p = 2)
    classifier_knn.fit(X_train, y_train)

    y_pred = classifier_knn.predict(X_test)

    cm = confusion_matrix(y_test, y_pred)

    return print(f"Train score : {classifier_knn.score(X_train, y_train)}\nTest score : {classifier_knn.score(X_test, y_test)}")

def naive_classifier(X_train, X_test, y_train, y_test):
    
    classifier_naive = GaussianNB()
    classifier_naive.fit(X_train, y_train)

    y_pred = classifier_naive.predict(X_test)

    cm = confusion_matrix(y_test, y_pred)

    return print(f"Train score : {classifier_naive.score(X_train, y_train)}\nTest score : {classifier_naive.score(X_test, y_test)}")

def tree_classifier(X_train, X_test, y_train, y_test):
    
    classifier_tree = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)
    classifier_tree.fit(X_train, y_train)

    y_pred = classifier_tree.predict(X_test)

    cm = confusion_matrix(y_test, y_pred)

    return print(f"Train score : {classifier_tree.score(X_train, y_train)}\nTest score : {classifier_tree.score(X_test, y_test)}")

def forest_classifier(X_train, X_test, y_train, y_test):
    classifier_forest = RandomForestClassifier(criterion = 'entropy', random_state = 0)
    classifier_forest.fit(X_train, y_train)

    y_pred = classifier_forest.predict(X_test)

    cm = confusion_matrix(y_test, y_pred)

    return print(f"Train score : {classifier_forest.score(X_train, y_train)}\nTest score : {classifier_forest.score(X_test, y_test)}")

def logistic_regression (X_train,X_test,y_train,y_test):

  from sklearn.linear_model import LogisticRegression
  model = LogisticRegression(random_state = 0)
  model.fit(X_train, y_train)
  y_pred = model.predict(X_test)
  cm = confusion_matrix(y_test, y_pred)
  
  return print(f"Train score : {model.score(X_train, y_train)}\nTest score : {model.score(X_test, y_test)}")

def print_score(X_train, X_test, y_train, y_test):
    print("SVM:\n")
    svm_classifier(X_train, X_test, y_train, y_test)

    print("-"*100)
    print()

    print("KNN:\n")
    knn_classifier(X_train, X_test, y_train, y_test)

    print("-"*100)
    print()

    print("Naive:\n")
    naive_classifier(X_train, X_test, y_train, y_test)

    print("-"*100)
    print()

    print("Decision Tree:\n")
    tree_classifier(X_train, X_test, y_train, y_test)

    print("-"*100)
    print()

    print("Random Forest:\n")
    forest_classifier(X_train, X_test, y_train, y_test)

    print("-"*100)
    print()

    print("Logistic Regression:\n")
    forest_classifier(X_train, X_test, y_train, y_test)

print_score(X_train, X_test, y_train, y_test)

classifier_forest = RandomForestClassifier(criterion = 'entropy')
classifier_forest.fit(X_train, y_train)
y_pred = classifier_forest.predict(X_test)

cm = confusion_matrix(y_test, y_pred)
cm
print(cm)

pd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True)

#from xgboost import XGBClassifier 
#from sklearn.model_selection import train_test_split 
#from sklearn.metrics import accuracy_score 

#model=XGBClassifier() 
#model.fit(X_train,y_train) 
#y_pred=model.predict(X_test) 
#accu=accuracy_score(y_test,y_pred) 
#accu=accuracy_score(y_test,y_pred) 
#print(accu)

#from sklearn.ensemble import BaggingClassifier 
#from sklearn.metrics import accuracy_score 
#model = BaggingClassifier() 
#model.fit(X_train,y_train) 
#y_pred=model.predict(X_test) 
#accu=accuracy_score(y_test,y_pred) 
#accu=accuracy_score(y_test,y_pred) 
#print(accu)

import pickle
filename = 'Depression.pkl' 
pickle.dump(classifier_forest, open(filename, 'wb'))
#model = open('Depression.pkl','rb')
#y_pred = classifier_forest.predict(X_test)